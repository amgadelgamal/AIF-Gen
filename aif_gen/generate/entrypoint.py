import argparse
import asyncio
import pathlib
import time

from aif_gen.api.response_mapper import ResponseMapper
from aif_gen.dataset import AlignmentDataset
from aif_gen.generate.service import process_prompts
from aif_gen.task import AlignmentTask, Domain

parser = argparse.ArgumentParser(
    description='Generate an AlignmentDataset',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter,
)
parser.add_argument(
    '--model_name', type=str, required=True, help='OpenAI compatible model alias.'
)
parser.add_argument(
    '--output_path',
    type=str,
    default=f'data/{time.time()}',
    help='Path to directory where to save the dataset.',
)
parser.add_argument(
    '--save_frequency',
    type=int,
    default=500,
    help='Number of samples to batch write to disc.',
)
parser.add_argument(
    '--max_concurrency',
    type=int,
    default=256,
    help='Max number of concurrent API inference requests to the language model.',
)
parser.add_argument(
    '--num_samples',
    type=int,
    default=1000,
    help='Number of response pairs to generate for th egiven task prompt.',
)


async def main() -> None:
    args = parser.parse_args()
    async_semaphore = asyncio.Semaphore(args.max_concurrency)

    output_path = pathlib.Path(args.output_path)
    output_path.mkdir(parents=True, exist_ok=True)

    task = get_mock_alignment_task()

    print('Model:', args.model_name)
    print('Output folder:', args.output_path)
    print('Task:', task)

    prompts = []
    prompts.append(generate_mock_prompt(task, args.num_samples))

    # Save occasionally.
    batch_index: int = 0
    dataset = AlignmentDataset(task, [])
    async for sample in process_prompts(
        prompts, model_name=args.model_name, async_semaphore=async_semaphore
    ):
        if sample is not None:
            dataset.append(sample)

        if (len(dataset) + 1) % args.save_frequency == 0:
            output_file_path = output_path / f'output_{batch_index:03d}.json'
            dataset.to_json(output_file_path)
            dataset = AlignmentDataset(task, [])  # Should be able to just clear it
            batch_index += 1

    output_file_path = output_path / f'output_{batch_index:03d}.json'
    dataset.to_json(output_file_path)


def generate_mock_prompt(task: AlignmentTask, num_samples: int) -> str:
    # In theory, this would have been generated by the prompt mapper
    task_prompt = task.objective

    response_mapper = ResponseMapper()
    prompt = response_mapper.generate_prompt(task, task_prompt, num_samples=num_samples)
    print(f'Using prompt:\n\n{prompt}')
    return prompt


def get_mock_alignment_task() -> AlignmentTask:
    component_dict = {
        'Healthcare': {
            'seed_words': ['hospital', 'exercise', 'medicine'],
        },
        'Technology': {
            'seed_words': ['engineering', 'AI', 'internet'],
        },
    }
    domain = Domain.from_dict(component_dict)
    objective = 'Generate a news article headline.'
    preference = 'Make the headline polarizing'

    task = AlignmentTask(domain, objective, preference)
    return task


if __name__ == '__main__':
    asyncio.run(main())
